# -*- coding: utf-8 -*-
"""TFM_General.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gQTZruzugiLcrKmqjK1PGWllf0gPXawV

# TFM - Predicción Energía Fotovoltaica con métodos de IA

## Tratamiento previo de los datos: cargar datos, transformar, limpiar ...
"""

import pandas as pd

#Acceso a Google Drive
from google.colab import drive
drive.mount('/content/drive')


# Lista de años para los que cargar los datos
years = ['2015']

# Cargar y combinar todos los archivos de Excel
data_meteo_list = [pd.read_excel(f'/content/drive/My Drive/MASTER BIG DATA/Sunlab-Faro-Meteo-{year}.xlsx') for year in years]
data_pv_list = [pd.read_excel(f'/content/drive/My Drive/MASTER BIG DATA/Sunlab-Faro-PV-{year}.xlsx') for year in years]

# Concatenar los datos de meteo y PV en un solo DataFrame para cada tipo
data_meteo = pd.concat(data_meteo_list, ignore_index=True)
data_pv = pd.concat(data_pv_list, ignore_index=True)

# Realizar la combinación utilizando "Datetime" como clave de unión
data_merged = pd.merge(data_meteo, data_pv, on='Datetime', how='inner')

# Imprimir las primeras filas del DataFrame resultante
print(data_merged.head())

# Lista de columnas a mantener
columnas_mantenidas = [
    'Datetime',
    'Ambient Temperature [ÂºC]',
    'Global Radiation [W/m2]',
    'Diffuse Radiation [W/m2]',
    'Ultraviolet [W/m2]',
    'Wind Velocity [m/s]',
    'Wind Direction [Âº]',
    'Precipitation [mm]',
    'Atmospheric pressure [hPa]',
    'A_Optimal - Voltage DC [V]',
    'A_Optimal - Current DC [A]',
    'A_Optimal - Power DC [W]',
    'A_Optimal - Temperature [ÂºC]',
]

# Crear un nuevo DataFrame solo con las columnas de interés
df = data_merged[columnas_mantenidas]

# Imprimir las primeras filas del nuevo DataFrame
print(df.head())

tipos_de_dato = df.dtypes
print(tipos_de_dato)

df['Datetime'] = pd.to_datetime(df['Datetime'])

df.head()

import matplotlib.pyplot as plt

# Establecer la columna 'Datetime' como el índice del DataFrame
df.set_index('Datetime', inplace=True)

# Resample a frecuencia mensual y calcular la media de la potencia óptima para cada mes
monthly_data = df['A_Optimal - Power DC [W]'].resample('W').sum()

# Graficar la potencia óptima mensual en función de la fecha
plt.figure(figsize=(10, 6))
plt.plot(monthly_data.index, monthly_data, linestyle='-')
plt.title('Potencia Anual (W)')
plt.xlabel('Fecha')
plt.ylabel('Potencia [W]')
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""### Limpieza de datos"""

# Count the number of null values for each column
na_values = df.isnull().sum()
na_column = na_values / len(df) * 100
print("Porcentaje de valores nulos por columna (%): ")
print(na_column)

# Definir el tamaño de la figura
plt.figure(figsize=(12, 6))

# Graficar el porcentaje de valores nulos por columna
na_column.plot(kind='bar')

# Añadir título y etiquetas a los ejes
plt.title("Porcentaje de valores nulos por columna")
plt.xlabel("Columnas")
plt.ylabel("Porcentaje de valores nulos (%)")

# Mostrar el gráfico
plt.show()

# Eliminar columnas con más del 80% de valores nulos
columnas_a_eliminar = df.columns[na_column > 80]
df_clean = df.drop(columnas_a_eliminar, axis=1)
# Imputación de valores nulos con interpolación lineal
data_interpolado1 = df_clean.interpolate(method='linear')
print("Interpolación lineal: ",data_interpolado1.shape)

data_interpolado = data_interpolado1.dropna()
data_interpolado.shape

nulos_final = data_interpolado.isnull().sum()

print("Valores nulos por columna después de aplicar el método interpolación: ", nulos_final)

# Calcular el rango intercuartílico (IQR)
Q1 = data_interpolado.quantile(0.25)
Q3 = data_interpolado.quantile(0.75)
IQR = Q3 - Q1

# Contar los valores atípicos por columna
outliers_count = ((data_interpolado < (Q1 - 1.5 * IQR)) | (data_interpolado > (Q3 + 1.5 * IQR))).sum()

# Visualizar el conteo de valores atípicos
outliers_count.sort_values(ascending=False, inplace=True)
print(outliers_count)

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
outliers_count.plot(kind='bar')
plt.xlabel('Columnas')
plt.ylabel('Número de Valores Atípicos')
plt.title('Número de Valores Atípicos por Columna')
plt.show()

# Estadísticas descriptivas de las columnas
descripcion = data_interpolado[['A_Optimal - Voltage DC [V]', 'Diffuse Radiation [W/m2]', 'Wind Velocity [m/s]']].describe()
print(descripcion)

# Calcular el rango intercuartílico (IQR)
Q1 = descripcion.loc['25%']
Q3 = descripcion.loc['75%']
IQR = Q3 - Q1

# Calcular los límites superior e inferior para detectar outliers
limite_inferior = Q1 - 1.5 * IQR
limite_superior = Q3 + 1.5 * IQR

print("Límite inferior:")
print(limite_inferior)
print("\nLímite superior:")
print(limite_superior)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Calcula la puntuación Z para una columna específica
def calcular_z_score(columna):
    mean = columna.mean()
    std_dev = columna.std()
    z_scores = (columna - mean) / std_dev
    return z_scores

# Suponiendo que 'df' es tu DataFrame y 'columna' es la columna en la que quieres calcular los Z-Scores
columna = 'A_Optimal - Voltage DC [V]'
z_scores = calcular_z_score(data_interpolado[columna])

# Graficar los Z-Scores
plt.figure(figsize=(10, 6))
sns.histplot(z_scores, kde=True)
plt.title('Distribución de Z-Scores para la columna "{}"'.format(columna))
plt.xlabel('Z-Score')
plt.ylabel('Frecuencia')
plt.axvline(x=3, color='r', linestyle='--')
plt.axvline(x=-3, color='r', linestyle='--')
plt.xlim(-7,4)
plt.legend()
plt.show()

import pandas as pd
import numpy as np

# Función para calcular los Z-Scores para todas las columnas en el DataFrame
def calcular_z_scores(df):
    z_scores = pd.DataFrame()
    for columna in df.columns:
        if np.issubdtype(df[columna].dtype, np.number):
            z_scores[columna] = (data_interpolado[columna] - data_interpolado[columna].mean()) / data_interpolado[columna].std()
    return z_scores

# Función para filtrar outliers basados en los Z-Scores
def filtrar_outliers_z_score(data_interpolado, umbral_z_score=3):
    z_scores = calcular_z_scores(data_interpolado)
    outliers_index = z_scores[(abs(z_scores) > umbral_z_score).any(axis=1)].index
    df_filtrado = data_interpolado.drop(outliers_index)
    return df_filtrado

# Aplicar el método Z-Score para filtrar outliers en el DataFrame df_clean
df_final = filtrar_outliers_z_score(data_interpolado)

# Mostrar la forma del DataFrame final
print("Forma del DataFrame final después de filtrar outliers:", df_final.shape)

# Calcular el rango intercuartílico (IQR)
Q1 = data_interpolado.quantile(0.25)
Q3 = data_interpolado.quantile(0.75)
IQR = Q3 - Q1

# Filtrar outliers
data_sin_outliers = data_interpolado[~((data_interpolado < (Q1 - 1.5 * IQR)) | (data_interpolado > (Q3 + 1.5 * IQR))).any(axis=1)]
df_final = data_sin_outliers
df_final.shape

#Dataframe final
df_final.head()

from sklearn.preprocessing import MinMaxScaler
import seaborn as sns
# Eliminar la columna de fechas u otras columnas no numéricas
#df_numeric = df_final.drop(columns=['Datetime'])

# Normalizar los datos
scaler = MinMaxScaler()
df_normalized = scaler.fit_transform(df_final)

# Convertir el array normalizado de nuevo en un DataFrame
df_normalized = pd.DataFrame(df_normalized, columns=df_final.columns)

# Calcular la matriz de correlación con los datos normalizados
correlation_matrix_normalized = df_normalized.corr()

# Visualizar el mapa de calor de la matriz de correlación normalizada
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix_normalized, annot=True, cmap='coolwarm', fmt=".2f", vmin=-1, vmax=1)
plt.show()

# Datos para predecir

data = df_normalized
data.head()

"""## Modelos ML básicos: LinearRegression, RandomForest...

"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# Eliminar la columna altamente correlacionada 'A_Optimal - Current DC [A]'
X = df_normalized.drop(columns=['A_Optimal - Current DC [A]','A_Optimal - Power DC [W]'])
y = df_normalized['A_Optimal - Power DC [W]']

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crear y entrenar el modelo de regresión lineal
regression_model = LinearRegression()
regression_model.fit(X_train, y_train)

# Predecir sobre el conjunto de prueba
predictions = regression_model.predict(X_test)

# Calcular el error cuadrático medio (MSE)
mse = mean_squared_error(y_test, predictions)
print("Error cuadrático medio (MSE) del modelo de regresión lineal:", mse)

# Calcular el coeficiente de determinación (R^2)
r2 = r2_score(y_test, predictions)
print("Coeficiente de determinación (R^2):", r2)

# Calcular el error absoluto medio (MAE)
mae = mean_absolute_error(y_test, predictions)
print("Error absoluto medio (MAE):", mae)

plt.figure(figsize=(10, 6))
plt.scatter(y_test, predictions)
plt.xlabel('Valores reales')
plt.ylabel('Predicciones')
plt.title('Predicciones vs Valores reales')
plt.show()

residuals = y_test - predictions
plt.figure(figsize=(10, 6))
plt.hist(residuals, bins=30, edgecolor='k')
plt.xlabel('Residuos')
plt.ylabel('Frecuencia')
plt.title('Histograma de Residuos')
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# Eliminar la columna altamente correlacionada 'A_Optimal - Current DC [A]'
X = df_final.drop(columns=['A_Optimal - Current DC [A]','A_Optimal - Power DC [W]', 'A_Optimal - Voltage DC [V]'])
y = df_final['A_Optimal - Power DC [W]']

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crear y entrenar el modelo de regresión lineal
regression_model = LinearRegression()
regression_model.fit(X_train, y_train)

# Predecir sobre el conjunto de prueba
predictions = regression_model.predict(X_test)

# Calcular el error cuadrático medio (MSE)
mse = mean_squared_error(y_test, predictions)
print("Error cuadrático medio (MSE) del modelo de regresión lineal:", mse)

# Calcular el coeficiente de determinación (R^2)
r2 = r2_score(y_test, predictions)
print("Coeficiente de determinación (R^2):", r2)

# Calcular el error absoluto medio (MAE)
mae = mean_absolute_error(y_test, predictions)
print("Error absoluto medio (MAE):", mae)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.linear_model import ElasticNet
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# Suponiendo que df_final ya está definido y contiene tus datos

# Eliminar las columnas altamente correlacionadas
X = df_final.drop(columns=['A_Optimal - Current DC [A]', 'A_Optimal - Power DC [W]', 'A_Optimal - Voltage DC [V]'])
y = df_final['A_Optimal - Power DC [W]']

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crear y entrenar el modelo de regresión lineal estándar
linear_model = LinearRegression()
linear_model.fit(X_train, y_train)
linear_predictions = linear_model.predict(X_test)

# Calcular las métricas para el modelo de regresión lineal estándar
linear_r2 = r2_score(y_test, linear_predictions)
linear_mse = mean_squared_error(y_test, linear_predictions)
linear_mae = mean_absolute_error(y_test, linear_predictions)

print("Regresión Lineal Estándar:")
print("Coeficiente de determinación (R^2):", linear_r2)
print("Error cuadrático medio (MSE):", linear_mse)
print("Error absoluto medio (MAE):", linear_mae)

# Definir la cuadrícula de parámetros para `alpha`
alpha_values = np.logspace(-2, 1.5, 50)

# Inicializar listas para almacenar los resultados
ridge_r2_scores = []
lasso_r2_scores = []
elasticnet_r2_scores = []

# Iterar sobre los valores de alpha
for alpha in alpha_values:
    # Crear y entrenar el modelo de regresión Ridge
    ridge_model = Ridge(alpha=alpha)
    ridge_model.fit(X_train, y_train)
    ridge_predictions = ridge_model.predict(X_test)
    ridge_r2_scores.append(r2_score(y_test, ridge_predictions))

    # Crear y entrenar el modelo de regresión Lasso
    lasso_model = Lasso(alpha=alpha, max_iter=10000)  # Aumentar max_iter para asegurar la convergencia
    lasso_model.fit(X_train, y_train)
    lasso_predictions = lasso_model.predict(X_test)
    lasso_r2_scores.append(r2_score(y_test, lasso_predictions))


# Graficar los resultados
plt.figure(figsize=(10, 6))
plt.plot(alpha_values, ridge_r2_scores, label='Ridge Regression', marker='o')
plt.plot(alpha_values, lasso_r2_scores, label='Lasso Regression', marker='o')
#plt.plot(alpha_values, elasticnet_r2_scores, label='ElasticNet Regression', marker='o')
plt.axhline(y=linear_r2, color='r', linestyle='-', label='Linear Regression')
plt.xscale('log')
plt.xlabel('λ')
plt.ylabel('R^2 Score')
plt.title('Coeficiente de determinación para modelos de regularización en función de λ')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.linear_model import ElasticNet
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# Suponiendo que df_final ya está definido y contiene tus datos

# Eliminar las columnas altamente correlacionadas
X = df_final.drop(columns=['A_Optimal - Current DC [A]', 'A_Optimal - Power DC [W]', 'A_Optimal - Voltage DC [V]'])
y = df_final['A_Optimal - Power DC [W]']

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crear y entrenar el modelo de regresión lineal estándar
linear_model = LinearRegression()
linear_model.fit(X_train, y_train)
linear_predictions = linear_model.predict(X_test)

# Calcular las métricas para el modelo de regresión lineal estándar
linear_r2 = r2_score(y_test, linear_predictions)


print("Regresión Lineal Estándar:")
print("Coeficiente de determinación (R^2):", linear_r2)
print("Error cuadrático medio (MSE):", linear_mse)
print("Error absoluto medio (MAE):", linear_mae)

# Definir la cuadrícula de parámetros para `alpha`
alpha_values = np.logspace(-2, 2, 50)

# Inicializar listas para almacenar los resultados
ridge_r2_scores = []
ridge_mae_scores = []

# Iterar sobre los valores de alpha
for alpha in alpha_values:
    # Crear y entrenar el modelo de regresión Ridge
    ridge_model = Ridge(alpha=alpha)
    ridge_model.fit(X_train, y_train)
    ridge_predictions = ridge_model.predict(X_test)
    ridge_r2_scores.append(r2_score(y_test, ridge_predictions))
    ridge_mae_scores.append(mean_absolute_error(y_test, ridge_predictions))


# Graficar los resultados
plt.figure(figsize=(10, 6))
plt.plot(alpha_values, ridge_r2_scores, label='Ridge Regression', marker='o')
plt.axhline(y=linear_r2, color='r', linestyle='-', label='Linear Regression')
plt.xscale('log')
plt.xlabel('Alpha')
plt.ylabel('R^2 Score')
plt.title('R^2 Score en función de Alpha para Ridge, Lasso, ElasticNet y Linear Regression')
plt.legend()
plt.grid(True)
plt.show()


# Graficar los resultados
plt.figure(figsize=(10, 6))
plt.plot(alpha_values, ridge_mae_scores, label='Ridge Regression', marker='o')
plt.axhline(y=linear_r2, color='r', linestyle='-', label='Linear Regression')
plt.xscale('log')
plt.xlabel('Alpha')
plt.ylabel('R^2 Score')
plt.title('R^2 Score en función de Alpha para Ridge, Lasso, ElasticNet y Linear Regression')
plt.legend()
plt.grid(True)
plt.show()

"""### SVR"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# Suponiendo que df_final ya está definido y contiene tus datos

# Eliminar las columnas altamente correlacionadas
X = df_final.drop(columns=['A_Optimal - Current DC [A]', 'A_Optimal - Power DC [W]', 'A_Optimal - Voltage DC [V]'])
y = df_final['A_Optimal - Power DC [W]']

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crear y entrenar el modelo SVR
svr_model = SVR(kernel='rbf')  # Kernel radial (gaussiano)
svr_model.fit(X_train, y_train)

# Predecir sobre el conjunto de prueba
predictions = svr_model.predict(X_test)

# Calcular las métricas de evaluación
svr1_mse = mean_squared_error(y_test, predictions)
svr1_r2 = r2_score(y_test, predictions)
svr1_mae = mean_absolute_error(y_test, predictions)

# Imprimir las métricas
print("Error cuadrático medio (MSE) del modelo SVR:", svr1_mse)
print("Coeficiente de determinación (R^2) del modelo SVR:", svr1_r2)
print("Error absoluto medio (MAE) del modelo SVR:", svr1_mae)

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# Suponiendo que df_final ya está definido y contiene tus datos

# Eliminar las columnas altamente correlacionadas
X = df_final.drop(columns=['A_Optimal - Current DC [A]', 'A_Optimal - Power DC [W]', 'A_Optimal - Voltage DC [V]'])
y = df_final['A_Optimal - Power DC [W]']

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crear y entrenar el modelo SVR
svr_model = SVR(kernel='poly')  # Kernel radial (gaussiano)
svr_model.fit(X_train, y_train)

# Predecir sobre el conjunto de prueba
predictions = svr_model.predict(X_test)

# Calcular las métricas de evaluación
svr2_mse = mean_squared_error(y_test, predictions)
svr2_r2 = r2_score(y_test, predictions)
svr2_mae = mean_absolute_error(y_test, predictions)

# Imprimir las métricas
print("Error cuadrático medio (MSE) del modelo SVR:", svr2_mse)
print("Coeficiente de determinación (R^2) del modelo SVR:", svr2_r2)
print("Error absoluto medio (MAE) del modelo SVR:", svr2_mae)

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# Suponiendo que df_final ya está definido y contiene tus datos

# Eliminar las columnas altamente correlacionadas
X = df_final.drop(columns=['A_Optimal - Current DC [A]', 'A_Optimal - Power DC [W]', 'A_Optimal - Voltage DC [V]'])
y = df_final['A_Optimal - Power DC [W]']

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crear y entrenar el modelo SVR
svr_model = SVR(kernel='linear')  # Linear
svr_model.fit(X_train, y_train)

# Predecir sobre el conjunto de prueba
predictions = svr_model.predict(X_test)

# Calcular las métricas de evaluación
svr3_mse = mean_squared_error(y_test, predictions)
svr3_r2 = r2_score(y_test, predictions)
svr3_mae = mean_absolute_error(y_test, predictions)

# Imprimir las métricas
print("Error cuadrático medio (MSE) del modelo SVR:", svr3_mse)
print("Coeficiente de determinación (R^2) del modelo SVR:", svr3_r2)
print("Error absoluto medio (MAE) del modelo SVR:", svr3_mae)

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# Suponiendo que df_final ya está definido y contiene tus datos

# Eliminar las columnas altamente correlacionadas
X = df_final.drop(columns=['A_Optimal - Current DC [A]', 'A_Optimal - Power DC [W]', 'A_Optimal - Voltage DC [V]'])
y = df_final['A_Optimal - Power DC [W]']

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crear y entrenar el modelo SVR
svr_model = SVR(kernel='sigmoid')  # Sigmoidal
svr_model.fit(X_train, y_train)

# Predecir sobre el conjunto de prueba
predictions = svr_model.predict(X_test)

# Calcular las métricas de evaluación
svr4_mse = mean_squared_error(y_test, predictions)
svr4_r2 = r2_score(y_test, predictions)
svr4_mae = mean_absolute_error(y_test, predictions)

# Imprimir las métricas
print("Error cuadrático medio (MSE) del modelo SVR:", svr4_mse)
print("Coeficiente de determinación (R^2) del modelo SVR:", svr4_r2)
print("Error absoluto medio (MAE) del modelo SVR:", svr4_mae)

# Verifica los nombres de las columnas
print(df_final.columns)

"""### kNN"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import r2_score

# Suponiendo que df_final ya está definido y contiene tus datos

# Eliminar las columnas altamente correlacionadas
X = df_final.drop(columns=['A_Optimal - Current DC [A]', 'A_Optimal - Power DC [W]', 'A_Optimal - Voltage DC [V]'])
y = df_final['A_Optimal - Power DC [W]']

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Definir la lista de valores para n_neighbors
n_neighbors_values = range(1, 11)  # Por ejemplo, desde 1 hasta 20 vecinos

# Inicializar listas para almacenar los resultados de R^2 para cada métrica
r2_scores_euclidean = []
r2_scores_manhattan = []
r2_scores_minkowski = []

# Iterar sobre los valores de n_neighbors para cada métrica
for n_neighbors in n_neighbors_values:
    # Euclidean (default)
    knn_model_euclidean = KNeighborsRegressor(n_neighbors=n_neighbors)
    knn_model_euclidean.fit(X_train, y_train)
    predictions_euclidean = knn_model_euclidean.predict(X_test)
    r2_euclidean = r2_score(y_test, predictions_euclidean)
    r2_scores_euclidean.append(r2_euclidean)

    # Manhattan
    knn_model_manhattan = KNeighborsRegressor(n_neighbors=n_neighbors, metric='manhattan')
    knn_model_manhattan.fit(X_train, y_train)
    predictions_manhattan = knn_model_manhattan.predict(X_test)
    r2_manhattan = r2_score(y_test, predictions_manhattan)
    r2_scores_manhattan.append(r2_manhattan)

    # Minkowski (default with p=2 which is euclidean, but let's use p=3 for a different case)
    knn_model_minkowski = KNeighborsRegressor(n_neighbors=n_neighbors, metric='minkowski', p=3)
    knn_model_minkowski.fit(X_train, y_train)
    predictions_minkowski = knn_model_minkowski.predict(X_test)
    r2_minkowski = r2_score(y_test, predictions_minkowski)
    r2_scores_minkowski.append(r2_minkowski)

# Graficar los resultados
plt.figure(figsize=(12, 8))
plt.plot(n_neighbors_values, r2_scores_euclidean, marker='o', label='Euclidean')
plt.plot(n_neighbors_values, r2_scores_manhattan, marker='s', label='Manhattan')
plt.plot(n_neighbors_values, r2_scores_minkowski, marker='^', label='Minkowski')
plt.xlabel('Número de Vecinos')
plt.ylabel('Coeficiente de Determinación (R^2)')
plt.title('Coeficiente de determinación en función del número de vecinos para diferentes métricas de distancia')
plt.xticks(n_neighbors_values)
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import r2_score

# Suponiendo que df_final ya está definido y contiene tus datos

# Eliminar las columnas altamente correlacionadas
X = df_final.drop(columns=['A_Optimal - Current DC [A]', 'A_Optimal - Power DC [W]', 'A_Optimal - Voltage DC [V]'])
y = df_final['A_Optimal - Power DC [W]']

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# Crear y entrenar el modelo kNN
knn_model = KNeighborsRegressor(n_neighbors=8,metric='manhattan')
knn_model.fit(X_train, y_train)

# Predecir sobre el conjunto de prueba
knn_predictions = knn_model.predict(X_test)

# Calcular el error cuadrático medio (MSE) para el árbol de decisión
knn_mse = mean_squared_error(y_test, knn_predictions)
print("Error cuadrático medio (MSE) del árbol de decisión:", knn_mse)

# Calcular el coeficiente de determinación (R^2) para el árbol de decisión
knn_r2 = r2_score(y_test, knn_predictions)
print("Coeficiente de determinación (R^2) del árbol de decisión:", knn_r2)

# Calcular el error absoluto medio (MAE) para el árbol de decisión
knn_mae = mean_absolute_error(y_test, knn_predictions)
print("Error absoluto medio (MAE) del árbol de decisión:", knn_mae)

"""### Árboles de decisión"""

# Importar las bibliotecas necesarias
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Crear el modelo de árbol de decisión
dt_model = DecisionTreeRegressor(max_depth=11, random_state=42)

# Entrenar el modelo con los datos de entrenamiento
dt_model.fit(X_train, y_train)

# Predecir sobre el conjunto de prueba
dt_predictions = dt_model.predict(X_test)

# Calcular el error cuadrático medio (MSE) para el árbol de decisión
dt_mse = mean_squared_error(y_test, dt_predictions)
print("Error cuadrático medio (MSE) del árbol de decisión:", dt_mse)

# Calcular el coeficiente de determinación (R^2) para el árbol de decisión
dt_r2 = r2_score(y_test, dt_predictions)
print("Coeficiente de determinación (R^2) del árbol de decisión:", dt_r2)

# Calcular el error absoluto medio (MAE) para el árbol de decisión
dt_mae = mean_absolute_error(y_test, dt_predictions)
print("Error absoluto medio (MAE) del árbol de decisión:", dt_mae)

import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import r2_score

# Lista de valores de max_depth que deseas evaluar
max_depth_values = list(range(1, 20))

# Lista para almacenar los valores de R^2
r2_scores = []

# Evaluar el rendimiento para diferentes valores de max_depth
for max_depth in max_depth_values:
    # Crear el modelo de árbol de decisión con el valor actual de max_depth
    dt_model = DecisionTreeRegressor(max_depth=max_depth, random_state=42)

    # Entrenar el modelo con los datos de entrenamiento
    dt_model.fit(X_train, y_train)

    # Predecir sobre el conjunto de prueba
    dt_predictions = dt_model.predict(X_test)

    # Calcular el coeficiente de determinación (R^2) para el árbol de decisión
    dt_r2 = r2_score(y_test, dt_predictions)

    # Almacenar el R^2 para este max_depth
    r2_scores.append(dt_r2)

# Encontrar el índice del valor máximo de R^2
max_r2_index = r2_scores.index(max(r2_scores))
max_r2_value = r2_scores[max_r2_index]
max_r2_depth = max_depth_values[max_r2_index]

# Graficar el coeficiente de determinación (R^2) en función de max_depth
plt.figure(figsize=(8, 6))
plt.plot(max_depth_values, r2_scores, marker='o')
plt.xlabel('Profundidad máxima del árbol (max_depth)')
plt.ylabel('R^2')
plt.title('R^2 en función de la profundidad máxima del árbol')

# Dibujar un círculo rojo en el punto máximo
plt.scatter(max_r2_depth, max_r2_value, color='red', s=100, zorder=5)
# Anotar el punto máximo en el gráfico
plt.text(max_r2_depth, max_r2_value - 0.05, f'Max R^2: {max_r2_value:.2f}\n(max_depth={max_r2_depth})',
         horizontalalignment='center', color='red', fontsize=10)

plt.show()

"""### Random Forest"""

# Importar RandomForestRegressor desde sklearn
from sklearn.ensemble import RandomForestRegressor

# Crear y entrenar el modelo Random Forest
random_forest_model = RandomForestRegressor(random_state=42)
random_forest_model.fit(X_train, y_train)

# Predecir sobre el conjunto de prueba
rf_predictions = random_forest_model.predict(X_test)

# Calcular el error cuadrático medio (MSE) para Random Forest
rf_mse = mean_squared_error(y_test, rf_predictions)
print("Error cuadrático medio (MSE) de Random Forest:", rf_mse)

# Calcular el coeficiente de determinación (R^2) para Random Forest
rf_r2 = r2_score(y_test, rf_predictions)
print("Coeficiente de determinación (R^2) de Random Forest:", rf_r2)

# Calcular el error absoluto medio (MAE) para Random Forest
rf_mae = mean_absolute_error(y_test, rf_predictions)
print("Error absoluto medio (MAE) de Random Forest:", rf_mae)

import matplotlib.pyplot as plt
import pandas as pd

# Asegúrate de que el índice de df_final esté configurado con 'Datetime' y que sea de tipo datetime64[ns]
df_final.index = pd.to_datetime(df_final.index)

# Filtrar los datos para el mes específico
mes_especifico = '2015-05'

# Seleccionar los datos para el mes específico
datos_mes = df_final.loc[mes_especifico]

# Si no hay datos para el mes seleccionado, mostrar un mensaje
if datos_mes.empty:
    print(f"No se encontraron datos para el mes {mes_especifico}")
else:
    # Calcular la potencia promedio real por hora para el mes
    potencia_real_promedio = datos_mes['A_Optimal - Power DC [W]'].resample('D').mean()

    # Obtener las características (X) para el mes seleccionado
    X_mes = datos_mes.drop(columns=['A_Optimal - Current DC [A]', 'A_Optimal - Power DC [W]', 'A_Optimal - Voltage DC [V]'])

    # Predicciones del modelo de Random Forest
    predicciones_rf_mes = random_forest_model.predict(X_mes)

    # Crear un DataFrame con las predicciones de Random Forest para calcular la potencia promedio
    predicciones_rf_df = pd.DataFrame(predicciones_rf_mes, index=datos_mes.index, columns=['Predicciones RF'])

    # Calcular las predicciones promedio de Random Forest por hora para el mes
    predicciones_rf_promedio = predicciones_rf_df['Predicciones RF'].resample('D').mean()

    # Crear un gráfico
    plt.figure(figsize=(10, 6))

    # Graficar la potencia promedio real
    plt.plot(potencia_real_promedio.index, potencia_real_promedio, label='Potencia Real', color='black', linewidth=0, marker='o')

    # Graficar las predicciones promedio de Random Forest
    plt.plot(predicciones_rf_promedio.index, predicciones_rf_promedio, label='Random Forest', color='green')

    # Añadir leyenda, etiquetas de ejes y título
    plt.legend()
    plt.xlabel('Día')
    plt.ylabel('Potencia Media [W]')
    plt.title(f'Predicción del modelo Random Forest para el mes {mes_especifico}')

    # Mostrar el gráfico
    plt.show()

from sklearn.model_selection import GridSearchCV

# Definir los hiperparámetros a optimizar
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [None, 10, 20, 30]
}

# Crear el modelo RandomForestRegressor
random_forest_model = RandomForestRegressor(random_state=42)

# Crear el objeto GridSearchCV con el modelo, los hiperparámetros a optimizar, y el número de pliegues de validación cruzada
grid_search = GridSearchCV(random_forest_model, param_grid, cv=5, scoring='r2', n_jobs=-1)

# Ejecutar la búsqueda de hiperparámetros
grid_search.fit(X_train, y_train)

# Obtener los mejores hiperparámetros
best_params = grid_search.best_params_

# Obtener el mejor modelo
best_model = grid_search.best_estimator_

# Imprimir los mejores hiperparámetros
print(f"Mejores hiperparámetros: {best_params}")

# Calcular el rendimiento del mejor modelo en el conjunto de prueba
y_pred = best_model.predict(X_test)
r2_best = r2_score(y_test, y_pred)

print(f"Coeficiente de determinación (R^2) del mejor modelo: {r2_best}")

"""### Boosting"""

from sklearn.ensemble import GradientBoostingRegressor


# Creación del modelo

gradient_model = GradientBoostingRegressor(random_state=42)

# Entrenamiento del modelo
gradient_model.fit(X_train, y_train)

# Predicciones en el conjunto de validación
gb_predictions = gradient_model.predict(X_test)

# Calcular el error cuadrático medio (MSE) para Random Forest
gb_mse = mean_squared_error(y_test, gb_predictions)
print("Error cuadrático medio (MSE) de Gradient Boosting:", gb_mse)

# Calcular el coeficiente de determinación (R^2) para Random Forest
gb_r2 = r2_score(y_test, gb_predictions)
print("Coeficiente de determinación (R^2) de Gradient Boosting:", gb_r2)

# Calcular el error absoluto medio (MAE) para Random Forest
gb_mae = mean_absolute_error(y_test, gb_predictions)
print("Error absoluto medio (MAE) de Gradient Boosting:", gb_mae)

from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint

# Definir el espacio de búsqueda de hiperparámetros
param_dist = {
    'n_estimators': randint(50, 500),
    'max_depth': randint(3, 10),
    'min_samples_split': randint(2, 20),
    'min_samples_leaf': randint(1, 20),
    'learning_rate': [0.001, 0.1, 0.3],
    'subsample': [0.5, 0.7, 1.0]
}

# Inicializar el modelo
gradient_model = GradientBoostingRegressor(random_state=42)

# Inicializar RandomizedSearchCV
random_search = RandomizedSearchCV(gradient_model, param_distributions=param_dist, n_iter=100, cv=5, scoring='neg_mean_squared_error', random_state=42)

# Realizar la búsqueda aleatoria
random_search.fit(X_train, y_train)

# Mostrar los mejores hiperparámetros encontrados
print("Mejores hiperparámetros:", random_search.best_params_)

# Entrenar el modelo con los mejores hiperparámetros
best_model = random_search.best_estimator_
best_model.fit(X_train, y_train)

# Predicciones en el conjunto de validación
gb_predictions = best_model.predict(X_test)

# Calcular el error cuadrático medio (MSE) para Gradient Boosting con los mejores hiperparámetros
gb_mse = mean_squared_error(y_test, gb_predictions)
print("Error cuadrático medio (MSE) de Gradient Boosting con los mejores hiperparámetros:", gb_mse)

# Calcular el coeficiente de determinación (R^2) para Gradient Boosting con los mejores hiperparámetros
gb_r2 = r2_score(y_test, gb_predictions)
print("Coeficiente de determinación (R^2) de Gradient Boosting con los mejores hiperparámetros:", gb_r2)

# Calcular el error absoluto medio (MAE) para Gradient Boosting con los mejores hiperparámetros
gb_mae = mean_absolute_error(y_test, gb_predictions)
print("Error absoluto medio (MAE) de Gradient Boosting con los mejores hiperparámetros:", gb_mae)

from sklearn.ensemble import BaggingRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# Crear y entrenar el modelo Random Forest
random_forest_model = RandomForestRegressor(random_state=42)
random_forest_model.fit(X_train, y_train)

# Predecir sobre el conjunto de prueba
rf_predictions = random_forest_model.predict(X_test)


# Creación del modelo base para Bagging
base_model = DecisionTreeRegressor(random_state=42)

# Creación del modelo Bagging
bagging_model = BaggingRegressor(base_model, n_estimators=10, random_state=42)

# Entrenamiento del modelo Bagging
bagging_model.fit(X_train, y_train)

# Predicciones en el conjunto de validación
bagging_predictions = bagging_model.predict(X_test)

# Calcular el error cuadrático medio (MSE) para Bagging
bagging_mse = mean_squared_error(y_test, bagging_predictions)
print("Error cuadrático medio (MSE) de Bagging:", bagging_mse)

# Calcular el coeficiente de determinación (R^2) para Bagging
bagging_r2 = r2_score(y_test, bagging_predictions)
print("Coeficiente de determinación (R^2) de Bagging:", bagging_r2)

# Calcular el error absoluto medio (MAE) para Bagging
bagging_mae = mean_absolute_error(y_test, bagging_predictions)
print("Error absoluto medio (MAE) de Bagging:", bagging_mae)

from sklearn.ensemble import BaggingRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import r2_score

# Definir una lista de valores para el número de estimadores
n_estimators_list = [10, 100, 200]

# Inicializar una lista para almacenar los valores de R^2
r2_scores = []

for n_estimators in n_estimators_list:
    # Crear el modelo Bagging con el número de estimadores actual
    bagging_model = BaggingRegressor(base_model, n_estimators=n_estimators, random_state=42)

    # Entrenar el modelo Bagging
    bagging_model.fit(X_train, y_train)

    # Realizar predicciones en el conjunto de validación
    bagging_predictions = bagging_model.predict(X_test)

    # Calcular el coeficiente de determinación (R^2)
    r2 = r2_score(y_test, bagging_predictions)

    # Agregar el valor de R^2 a la lista
    r2_scores.append(r2)

# Imprimir los valores de R^2 para cada número de estimadores
for i, n_estimators in enumerate(n_estimators_list):
    print(f"R^2 para {n_estimators} estimadores: {r2_scores[i]}")

import matplotlib.pyplot as plt
import pandas as pd
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# Asegúrate de que el índice de df_final esté configurado con 'Datetime' y que sea de tipo datetime64[ns]
df_final.index = pd.to_datetime(df_final.index)

# Filtrar los datos para la semana específica
fecha_inicio = '2015-01-01'
fecha_fin = '2015-06-01'

# Seleccionar los datos para la semana específica
datos_semana = df_final.loc[fecha_inicio:fecha_fin]

# Si no hay datos para la semana seleccionada, mostrar un mensaje
if datos_semana.empty:
    print(f"No se encontraron datos para la semana del {fecha_inicio} al {fecha_fin}")
else:
    # Calcular la potencia real promedio por hora para la semana
    potencia_real_promedio = datos_semana['A_Optimal - Power DC [W]'].resample('W').mean()

    # Obtener las características (X) para la semana seleccionada
    X_semana = datos_semana.drop(columns=['A_Optimal - Current DC [A]', 'A_Optimal - Power DC [W]', 'A_Optimal - Voltage DC [V]'])

    # Predicciones del modelo de Gradient Boosting
    gb_predictions_semana = gradient_model.predict(X_semana)

    # Crear un DataFrame con las predicciones de Gradient Boosting para calcular la potencia promedio
    gb_predicciones_df = pd.DataFrame(gb_predictions_semana, index=datos_semana.index, columns=['Predicciones GB'])

    # Calcular las predicciones promedio de Gradient Boosting por hora para la semana
    gb_predicciones_promedio = gb_predicciones_df['Predicciones GB'].resample('W').mean()

    # Crear un gráfico
    plt.figure(figsize=(10, 6))

    # Graficar la potencia promedio real
    plt.plot(potencia_real_promedio.index, potencia_real_promedio, label='Potencia Real', color='black', linewidth=0, marker='o')

    # Graficar las predicciones promedio de Gradient Boosting
    plt.plot(gb_predicciones_promedio.index, gb_predicciones_promedio, label='Gradient Boosting', color='blue')

    # Añadir leyenda, etiquetas de ejes y título
    plt.legend()
    plt.xlabel('Fecha')
    plt.ylabel('Potencia Media [W]')
    plt.title(f'Predicción del modelo Gradient Boosting para la semana del {fecha_inicio} al {fecha_fin}')





    # Mostrar el gráfico
    plt.show()

!pip install xgboost

import xgboost as xgb

# Eliminar caracteres no permitidos de los nombres de las características
X_train.columns = X_train.columns.str.replace('[\[\]\<\>]', '', regex=True)
X_test.columns = X_test.columns.str.replace('[\[\]\<\>]', '', regex=True)

# Creación del modelo
xgb_model = xgb.XGBRegressor(random_state=42, max_depth=15)

# Entrenamiento del modelo
xgb_model.fit(X_train, y_train)

# Predicciones en el conjunto de validación
xgb_predictions = xgb_model.predict(X_test)

# Calcular el error cuadrático medio (MSE) para XGBoost
xgb_mse = mean_squared_error(y_test, xgb_predictions)
print("Error cuadrático medio (MSE) de XGBoost:", xgb_mse)

# Calcular el coeficiente de determinación (R^2) para XGBoost
xgb_r2 = r2_score(y_test, xgb_predictions)
print("Coeficiente de determinación (R^2) de XGBoost:", xgb_r2)

# Calcular el error absoluto medio (MAE) para XGBoost
xgb_mae = mean_absolute_error(y_test, xgb_predictions)
print("Error absoluto medio (MAE) de XGBoost:", xgb_mae)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import cross_val_score
import xgboost as xgb

# Define un rango de profundidades para explorar
depths = np.arange(1, 20)

# Lista para almacenar los valores de R^2
r2_scores = []

# Itera sobre cada profundidad
for depth in depths:
    # Crea un modelo XGBoost con la profundidad dada
    xgb_model = xgb.XGBRegressor(max_depth=depth, random_state=42)

    # Calcula el R^2 utilizando validación cruzada
    r2 = cross_val_score(xgb_model, X_train, y_train, cv=5, scoring='r2').mean()

    # Almacena el resultado
    r2_scores.append(r2)

# Grafica los resultados
plt.plot(depths, r2_scores, marker='o')
plt.title('R^2 vs Profundidad del Árbol')
plt.xlabel('Profundidad del Árbol')
plt.ylabel('R^2')
plt.grid(True)
plt.show()

# Importar las bibliotecas necesarias
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# Asegúrate de que el índice de df_final esté configurado con 'Datetime' y que sea de tipo datetime64[ns]
df_final.index = pd.to_datetime(df_final.index)

# Filtra los datos para la fecha específica
fecha_especifica = '2014-05-11'

# Selecciona los datos para la fecha específica
datos_fecha = df_final.loc[fecha_especifica]

# Si no hay datos para la fecha seleccionada, muestra un mensaje
if datos_fecha.empty:
    print(f"No se encontraron datos para la fecha {fecha_especifica}")
else:
    # Calcular la potencia promedio real por hora
    potencia_real_promedio = datos_fecha['A_Optimal - Power DC [W]'].resample('H').mean()

    # Obtener las características (X) para la fecha seleccionada
    X_fecha = datos_fecha.drop(columns=['A_Optimal - Current DC [A]', 'A_Optimal - Power DC [W]', 'A_Optimal - Voltage DC [V]'])

    # Predicciones del modelo de regresión lineal
    predicciones_fecha = regression_model.predict(X_fecha)

    # Crear un DataFrame con las predicciones de regresión lineal para calcular la potencia promedio
    predicciones_df = pd.DataFrame(predicciones_fecha, index=datos_fecha.index, columns=['Predicciones'])

    # Calcular las predicciones promedio por hora
    predicciones_promedio = predicciones_df['Predicciones'].resample('H').mean()

    # Predicciones del modelo de Random Forest
    predicciones_rf_fecha = random_forest_model.predict(X_fecha)

    # Crear un DataFrame con las predicciones de Random Forest para calcular la potencia promedio
    predicciones_rf_df = pd.DataFrame(predicciones_rf_fecha, index=datos_fecha.index, columns=['Predicciones RF'])

    # Calcular las predicciones promedio de Random Forest por hora
    predicciones_rf_promedio = predicciones_rf_df['Predicciones RF'].resample('H').mean()

    # Predicciones del modelo de árbol de decisión
    predicciones_dt_fecha = dt_model.predict(X_fecha)

    # Crear un DataFrame con las predicciones de árbol de decisión para calcular la potencia promedio
    predicciones_dt_df = pd.DataFrame(predicciones_dt_fecha, index=datos_fecha.index, columns=['Predicciones DT'])

    # Calcular las predicciones promedio por hora para el modelo de árbol de decisión
    predicciones_dt_promedio = predicciones_dt_df['Predicciones DT'].resample('H').mean()

    # Predicciones del modelo gradient boosting
    predicciones_gb_fecha = gradient_model.predict(X_fecha)

    # Crear un DataFrame con las predicciones de árbol de decisión para calcular la potencia promedio
    predicciones_gb_df = pd.DataFrame(predicciones_gb_fecha, index=datos_fecha.index, columns=['Predicciones GB'])

    # Calcular las predicciones promedio por hora para el modelo de árbol de decisión
    predicciones_gb_promedio = predicciones_gb_df['Predicciones GB'].resample('H').mean()

    # Crear un gráfico
    plt.figure(figsize=(10, 6))

    # Graficar la potencia promedio real
    plt.plot(potencia_real_promedio.index, potencia_real_promedio, label='Potencia Real', color='black', linewidth=0, marker='o')

    # Graficar las predicciones promedio de regresión lineal
    plt.plot(predicciones_promedio.index, predicciones_promedio, label='Regresión Lineal', color='orange')

    # Graficar las predicciones promedio del árbol de decisión
    plt.plot(predicciones_dt_promedio.index, predicciones_dt_promedio, label='Árbol de Decisión', color='red')

    # Graficar las predicciones promedio de Random Forest
    plt.plot(predicciones_rf_promedio.index, predicciones_rf_promedio, label='Random Forest', color='green')


    # Graficar las predicciones promedio de Random Forest
    plt.plot(predicciones_gb_promedio.index, predicciones_gb_promedio, label='Gradient Boosting', color='blue')

    # Añadir leyenda, etiquetas de ejes y título
    plt.legend()
    plt.xlabel('Hora')
    plt.ylabel('Potencia Media [W]')
    plt.title(f'Predicción de los diferentes algoritmos de ML para el día {fecha_especifica}')

    # Formatear el eje x para mostrar solo las horas
    plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%H:%M'))
    plt.gca().xaxis.set_major_locator(plt.matplotlib.dates.HourLocator(interval=1))

    # Rotar las etiquetas del eje x para mayor legibilidad
    plt.gca().tick_params(axis='x', rotation=45)

    # Mostrar el gráfico
    plt.show()

"""

```
# Tiene formato de código
```

## Redes Neuronales y LSTM"""

# Importar bibliotecas necesarias
import numpy as np
import keras
from keras.models import Sequential
from keras.layers import Dense
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# Callback para detener el entrenamiento temprano
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Callback para reducir la tasa de aprendizaje si la pérdida de validación se estanca
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-6)


# Crear el modelo secuencial
model = Sequential()

# Añadir capas densas con activación relu
model.add(Dense(64, input_shape=(X_train.shape[1],), activation='relu'))
model.add(Dense(64, activation='relu'))

# Capa de salida con activación lineal
model.add(Dense(1))

# Compilar el modelo
model.compile(loss='mean_squared_error', optimizer='adam')

# Entrenar el modelo
# Ajusta el modelo con los nuevos callbacks
model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2, callbacks=[early_stopping, reduce_lr])
# Predecir sobre el conjunto de prueba
nn_predictions = model.predict(X_test)

# Calcular el error cuadrático medio (MSE)
nn_mse = mean_squared_error(y_test, nn_predictions)
print("Error cuadrático medio (MSE) de la red neuronal:", nn_mse)

# Calcular el coeficiente de determinación (R^2)
nn_r2 = r2_score(y_test, nn_predictions)
print("Coeficiente de determinación (R^2) de la red neuronal:", nn_r2)

# Calcular el error absoluto medio (MAE)
nn_mae = mean_absolute_error(y_test, nn_predictions)
print("Error absoluto medio (MAE) de la red neuronal:", nn_mae)

# Evaluar el modelo
nn_history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2, callbacks=[early_stopping, reduce_lr])

loss_nn = model.evaluate(X_test, y_test)
print(f'Loss RNN: {loss_nn}')

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))

# Gráfica de pérdida del modelo LSTM
plt.subplot(1, 2, 1)
plt.plot(nn_history.history['loss'], label='Entrenamiento')
plt.plot(nn_history.history['val_loss'], label='Validación')
plt.title('Pérdida RNA')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

# Importar bibliotecas necesarias
import numpy as np
import keras
from keras.models import Sequential
from keras.layers import Dense
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
import matplotlib.pyplot as plt

# Callback para detener el entrenamiento temprano
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Callback para reducir la tasa de aprendizaje si la pérdida de validación se estanca
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-6)

# Crear el modelo secuencial
model = Sequential()

# Añadir capas densas con activación relu
model.add(Dense(64, input_shape=(X_train.shape[1],), activation='relu'))
model.add(Dense(64, activation='relu'))

# Capa de salida con activación lineal
model.add(Dense(1))

# Compilar el modelo
model.compile(loss='mean_squared_error', optimizer='adam')

# Entrenar el modelo
nn_history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2, callbacks=[early_stopping, reduce_lr])

# Predecir sobre el conjunto de prueba
nn_predictions = model.predict(X_test)

# Calcular el error cuadrático medio (MSE)
nn_mse = mean_squared_error(y_test, nn_predictions)
print("Error cuadrático medio (MSE) de la red neuronal:", nn_mse)

# Calcular el coeficiente de determinación (R^2)
nn_r2 = r2_score(y_test, nn_predictions)
print("Coeficiente de determinación (R^2) de la red neuronal:", nn_r2)

# Calcular el error absoluto medio (MAE)
nn_mae = mean_absolute_error(y_test, nn_predictions)
print("Error absoluto medio (MAE) de la red neuronal:", nn_mae)

# Graficar la función de pérdida
plt.figure(figsize=(12, 6))

plt.plot(nn_history.history['loss'], label='Pérdida de Entrenamiento')
plt.plot(nn_history.history['val_loss'], label='Pérdida de Validación')
plt.title('Pérdida RNA')
plt.xlabel('Épocas')
plt.ylabel('Pérdida')
plt.legend()
plt.show()

# Graficar la función de pérdida
plt.figure(figsize=(10, 8))

plt.plot(nn_history.history['loss'], label='Entrenamiento')
plt.plot(nn_history.history['val_loss'], label='Validación')
plt.title('Pérdida RNA')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Importar las bibliotecas necesarias
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# Asegúrate de que el índice de df_final esté configurado con 'Datetime' y que sea de tipo datetime64[ns]
df_final.index = pd.to_datetime(df_final.index)

# Filtra los datos para la fecha específica
fecha_especifica = '2015-05-11'

# Selecciona los datos para la fecha específica
datos_fecha = df_final.loc[fecha_especifica]

# Si no hay datos para la fecha seleccionada, muestra un mensaje
if datos_fecha.empty:
    print(f"No se encontraron datos para la fecha {fecha_especifica}")
else:
    # Calcular la potencia promedio real por hora
    potencia_real_promedio = datos_fecha['A_Optimal - Power DC [W]'].resample('H').mean()

    # Obtener las características (X) para la fecha seleccionada
    X_fecha = datos_fecha.drop(columns=['A_Optimal - Current DC [A]', 'A_Optimal - Power DC [W]', 'A_Optimal - Voltage DC [V]'])

    # Predicciones del modelo de regresión lineal
    predicciones_fecha = model.predict(X_fecha)

    # Crear un DataFrame con las predicciones de regresión lineal para calcular la potencia promedio
    predicciones_df = pd.DataFrame(predicciones_fecha, index=datos_fecha.index, columns=['Predicciones'])

    # Calcular las predicciones promedio por hora
    predicciones_promedio = predicciones_df['Predicciones'].resample('H').mean()


    # Crear un gráfico
    plt.figure(figsize=(10, 6))

    # Graficar la potencia promedio real
    plt.plot(potencia_real_promedio.index, potencia_real_promedio, label='Potencia Real', color='black', linewidth=0, marker='o')

    # Graficar las predicciones promedio de regresión lineal
    plt.plot(predicciones_promedio.index, predicciones_promedio, label='Redes Neuronales Artificiales', color='red')


    # Añadir leyenda, etiquetas de ejes y título
    plt.legend()
    plt.xlabel('Hora')
    plt.ylabel('Potencia Media [W]')
    plt.title(f'Predicción para el día {fecha_especifica}')

    # Formatear el eje x para mostrar solo las horas
    plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%H:%M'))
    plt.gca().xaxis.set_major_locator(plt.matplotlib.dates.HourLocator(interval=1))

    # Rotar las etiquetas del eje x para mayor legibilidad
    plt.gca().tick_params(axis='x', rotation=45)

    # Mostrar el gráfico
    plt.show()

"""# Resumen"""

# Crear un DataFrame con los valores de R^2 y los nombres de los modelos
data = {
    'Modelo': ['Regresión Lineal', 'Árbol de Decisión', 'Random Forest', 'Gradient Boosting', 'XGBoost', 'Bagging', 'Redes Neuronales'],
    'R2 Score': [r2, knn_r2, dt_r2, rf_r2, gb_r2, xgb_r2, bagging_r2, nn_r2]
}
df = pd.DataFrame(data)

# Exportar el DataFrame a un archivo de Excel
df.to_excel('r2_scores.xlsx', index=False)

print("Los valores de R^2 se han exportado a 'r2_scores.xlsx'.")

import matplotlib.pyplot as plt
import numpy as np

# Definir los nombres de los modelos y las métricas
modelos = ['Regresión Lineal', 'kNN', 'Árbol de Decisión', 'Random Forest','Gradient Boosting', 'XGBoost', 'Bagging', 'Redes Neuronales']
mse_vals = [mse, knn_mse, dt_mse, rf_mse, gb_mse, xgb_mse, bagging_mse,  nn_mse]
r2_vals = [r2, knn_r2, dt_r2, rf_r2, gb_r2, xgb_r2, bagging_r2, nn_r2]
mae_vals = [mae, knn_mae, dt_mae, rf_mae, gb_mae, xgb_mae, bagging_mae, nn_mae]

# Configurar el número de gráficos y el tamaño de la figura
fig, axs = plt.subplots(3, 1, figsize=(8, 9), sharex=True)  # Usar sharex=True para compartir el eje X
plt.subplots_adjust(hspace=0)  # Ajustar el espacio vertical entre los subgráficos

# Gráfico de barras para MSE
axs[0].bar(modelos, mse_vals, color='lightblue')
axs[0].set_ylabel('MSE')
axs[0].set_title('Métricas de error para cada algoritmo implementado')

# Gráfico de barras para R^2
axs[1].bar(modelos, r2_vals, color='lightgreen')
axs[1].set_ylabel('R^2')
#axs[1].set_title('Coeficiente de Determinación (R^2) por Modelo')

# Gráfico de barras para MAE
axs[2].bar(modelos, mae_vals, color='lightcoral')
axs[2].set_ylabel('MAE')
#axs[2].set_title('Error Absoluto Medio (MAE) por Modelo')

# Rotar las etiquetas del eje x para mayor legibilidad
for ax in axs:
    ax.tick_params(axis='x', rotation=90)

# Mostrar los gráficos
plt.tight_layout()
plt.show()

# Crear un DataFrame con los datos
resultados_df = pd.DataFrame({
    'Modelo': modelos,
    'MSE': mse_vals,
    'R^2': r2_vals,
    'MAE': mae_vals
})

# Imprimir la tabla de resultados
print(resultados_df)